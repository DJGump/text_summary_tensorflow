{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","provenance":[],"mount_file_id":"1wfFjNvzmmzW97Q-_E0aLQUbCp2hRbHak","authorship_tag":"ABX9TyNOJhNlxcDHqNf94/PQbQyo"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rPimKP6s4f51","executionInfo":{"status":"ok","timestamp":1606953369182,"user_tz":300,"elapsed":6985,"user":{"displayName":"Dillan Gump","photoUrl":"","userId":"17565234147287955935"}},"outputId":"8c49ded4-9c0e-4cd6-e630-f7ac524b5095"},"source":["from keras import backend as K \n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Input, LSTM, RepeatVector, TimeDistributed, Concatenate\n","from keras.layers import Flatten\n","from keras.layers.embeddings import Embedding\n","from tensorflow.keras.preprocessing.text import one_hot\n","\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Input, LSTM, RepeatVector, TimeDistributed, Concatenate\n","from keras.layers import Flatten\n","from keras.layers.embeddings import Embedding\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from sklearn.model_selection import train_test_split as tts\n","import tensorflow as tf\n","\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import re\n","import nltk\n","from gensim.summarization import summarize\n","import spacy\n","\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from nltk.corpus import stopwords   \n","nltk.download('stopwords')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"S3fD2aNk4lML"},"source":["import tensorflow as tf\n","import os\n","from tensorflow.python.keras.layers import Layer\n","from tensorflow.python.keras import backend as K\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"INcKQCAv4ozY"},"source":["from keras.models import load_model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oq-UaROF6BUK","colab":{"base_uri":"https://localhost:8080/","height":231},"executionInfo":{"status":"error","timestamp":1606953738343,"user_tz":300,"elapsed":610,"user":{"displayName":"Dillan Gump","photoUrl":"","userId":"17565234147287955935"}},"outputId":"f7848a8a-a54c-429c-ab00-ef951c469bbd"},"source":["print(\"Size of vocabulary from the w2v model = {}\".format(vocab_size))\n","\n","\n","x_voc = X_voc_size\n","y_voc = y_voc_size\n","\n","src_text_length = max_length_article\n","sum_text_length = max_length_summary\n","\n","K.clear_session()\n","\n","latent_dim = 150\n","embedding_dim=100\n","\n","# Encoder\n","encoder_inputs = Input(shape=(src_text_length,))\n","\n","#embedding layer\n","enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n","\n","#encoder lstm 1\n","encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n","encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n","\n","#encoder lstm 2\n","encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n","encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n","\n","#encoder lstm 3\n","encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n","encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n","\n","# Set up the decoder, using `encoder_states` as initial state.\n","decoder_inputs = Input(shape=(None,))\n","\n","#embedding layer\n","dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n","dec_emb = dec_emb_layer(decoder_inputs)\n","\n","decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n","decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n","\n","#dense layer\n","decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n","decoder_outputs = decoder_dense(decoder_outputs)\n","\n","# Define the model \n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-a920a7bc42b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Size of vocabulary from the w2v model = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mx_voc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_voc_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_voc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_voc_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'vocab_size' is not defined"]}]},{"cell_type":"code","metadata":{"id":"Yhn_GI705Hkh"},"source":["model = load_model('/content/drive/MyDrive/DSIO6/Wiki Summary Bot/model1.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":231},"id":"7UIjsctV5QQn","executionInfo":{"status":"error","timestamp":1606953633393,"user_tz":300,"elapsed":910,"user":{"displayName":"Dillan Gump","photoUrl":"","userId":"17565234147287955935"}},"outputId":"50b39c28-538a-4ea2-f014-20ed06536c1e"},"source":["# this cell defines nessecary components, but IS NOT the flow of the process\n","# that is below\n","encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n","\n","# decoder inference\n","# store the previous states\n","decoder_state_input_h = Input(shape=(latent_dim,))\n","decoder_state_input_c = Input(shape=(latent_dim,))\n","decoder_hidden_state_input = Input(shape=(max_length_article, latent_dim))\n","\n","# get decoder embeddings\n","dec_emb2 = dec_emb_layer(decoder_inputs)\n","\n","# to predict the next word, set the the initial states from the previous step\n","decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n","\n","decoder_outputs = decoder_dense(decoder_outputs2)\n","\n","# Final decoder model\n","decoder_model = Model(\n","    [decoder_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n","    [decoder_outputs2] + [state_h2, state_c2]\n",")"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-1138c0dc9614>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# this cell defines nessecary components, but IS NOT the flow of the process\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# that is below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mencoder_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# decoder inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'encoder_inputs' is not defined"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BT7233_05mAb","executionInfo":{"status":"ok","timestamp":1606953681481,"user_tz":300,"elapsed":573,"user":{"displayName":"Dillan Gump","photoUrl":"","userId":"17565234147287955935"}},"outputId":"5a31843f-89cb-4407-b18f-fc4551c8ebb0"},"source":["model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"functional_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, 1419)]       0                                            \n","__________________________________________________________________________________________________\n","embedding (Embedding)           (None, 1419, 100)    3326800     input_1[0][0]                    \n","__________________________________________________________________________________________________\n","lstm (LSTM)                     [(None, 1419, 150),  150600      embedding[0][0]                  \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","lstm_1 (LSTM)                   [(None, 1419, 150),  180600      lstm[0][0]                       \n","__________________________________________________________________________________________________\n","embedding_1 (Embedding)         (None, None, 100)    1246900     input_2[0][0]                    \n","__________________________________________________________________________________________________\n","lstm_2 (LSTM)                   [(None, 1419, 150),  180600      lstm_1[0][0]                     \n","__________________________________________________________________________________________________\n","lstm_3 (LSTM)                   [(None, None, 150),  150600      embedding_1[0][0]                \n","                                                                 lstm_2[0][1]                     \n","                                                                 lstm_2[0][2]                     \n","__________________________________________________________________________________________________\n","time_distributed (TimeDistribut (None, None, 12469)  1882819     lstm_3[0][0]                     \n","==================================================================================================\n","Total params: 7,118,919\n","Trainable params: 7,118,919\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0x-hi8MY5zSR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606964793141,"user_tz":300,"elapsed":3303,"user":{"displayName":"Dillan Gump","photoUrl":"","userId":"17565234147287955935"}},"outputId":"85034c14-338d-4d4e-a5e9-3adcd43e108e"},"source":["!pip install pyyaml h5py  # Required to save models in HDF5 format\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (3.13)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.15.0)\n","Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.18.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"23VCP-lLkF0P"},"source":["import wikipedia"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LE7GSIs0kPde","executionInfo":{"status":"ok","timestamp":1606964819167,"user_tz":300,"elapsed":4907,"user":{"displayName":"Dillan Gump","photoUrl":"","userId":"17565234147287955935"}},"outputId":"31445402-9f52-43e1-b24a-98c87e36772a"},"source":["!pip install wikipedia"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting wikipedia\n","  Downloading https://files.pythonhosted.org/packages/67/35/25e68fbc99e672127cc6fbb14b8ec1ba3dfef035bf1e4c90f78f24a80b7d/wikipedia-1.4.0.tar.gz\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (4.6.3)\n","Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (2.23.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2020.11.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n","Building wheels for collected packages: wikipedia\n","  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for wikipedia: filename=wikipedia-1.4.0-cp36-none-any.whl size=11686 sha256=c810b1d51ee81d76b3b77321f2f63b7ec36d254ff58750a91801344cedd51153\n","  Stored in directory: /root/.cache/pip/wheels/87/2a/18/4e471fd96d12114d16fe4a446d00c3b38fb9efcb744bd31f4a\n","Successfully built wikipedia\n","Installing collected packages: wikipedia\n","Successfully installed wikipedia-1.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q-2KCQw3kSE3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607015552767,"user_tz":300,"elapsed":691,"user":{"displayName":"Dillan Gump","photoUrl":"","userId":"17565234147287955935"}},"outputId":"79029cbb-eff2-4102-d25a-c4e4544fabe1"},"source":["stop = False\n","tokens = [1,2,3,4,0,5]\n","\n","while not stop:\n","  for token in tokens:\n","    if token == 0:\n","      stop = True\n","      break\n","    print(token)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["1\n","2\n","3\n","4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9rzNrKH1lyrB"},"source":[""],"execution_count":null,"outputs":[]}]}